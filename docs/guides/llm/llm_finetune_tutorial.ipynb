{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üöÄ NeMo AutoModel - LLM Fine-Tuning Tutorial\n",
        "\n",
        "This notebook demonstrates how to fine-tune Large Language Models (LLMs) using NeMo AutoModel.\n",
        "\n",
        "It implements the same functionality as:\n",
        "```bash\n",
        "python examples/llm_finetune/finetune.py --config examples/llm_finetune/llama3_2/llama3_2_1b_squad.yaml\n",
        "```\n",
        "\n",
        "## What you'll learn:\n",
        "1. How to load and customize configurations\n",
        "2. How to set up the training recipe\n",
        "3. How to run the training loop\n",
        "4. How to customize training parameters\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!/usr/bin/python3 -m venv /root/.venvs/nemo_automodel\n",
        "\n",
        "# 2) Install tools + package into that venv\n",
        "!/root/.venvs/nemo_automodel/bin/python -m pip install -U pip setuptools wheel ipykernel\n",
        "!/root/.venvs/nemo_automodel/bin/python -m pip install -U nemo_automodel\n",
        "\n",
        "# 3) Register the venv as a Jupyter kernel\n",
        "!/root/.venvs/nemo_automodel/bin/python -m ipykernel install --user \\\n",
        "  --name nemo_automodel --display-name \"Python (nemo_automodel)\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "print(sys.executable)\n",
        "import sys, site\n",
        "print(\"exe:\", sys.executable)\n",
        "print(\"ENABLE_USER_SITE:\", site.ENABLE_USER_SITE)\n",
        "!{sys.executable} -m pip show nemo-automodel || true\n",
        "!{sys.executable} -m pip show nemo_automodel || true\n",
        "import sys\n",
        "\n",
        "# install the PyPI package (hyphen) into THIS kernel's venv\n",
        "!{sys.executable} -m pip install -U --no-user nemo-automodel\n",
        "\n",
        "# verify install location + import\n",
        "!{sys.executable} -m pip show nemo-automodel\n",
        "!{sys.executable} -c \"import nemo_automodel; print('OK:', nemo_automodel.__file__)\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# NeMo AutoModel imports\n",
        "from nemo_automodel.components.config.loader import load_yaml_config\n",
        "from nemo_automodel.recipes.llm.train_ft import TrainFinetuneRecipeForNextTokenPrediction\n",
        "\n",
        "print(\"‚úÖ NeMo AutoModel imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Configuration\n",
        "\n",
        "NeMo AutoModel uses YAML configuration files to define all training parameters.\n",
        "You can load a pre-defined config or create your own.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Option 1: Load a pre-defined config from examples\n",
        "CONFIG_PATH = \"/opt/Automodel/examples/llm_finetune/gemma/gemma_3_270m_squad.yaml\"\n",
        "import os\n",
        "os.environ[\"HF_TOKEN\"] = \"YOUR HF TOKEN\"\n",
        "# Load the YAML configuration\n",
        "cfg = load_yaml_config(CONFIG_PATH)\n",
        "#cfg.set_by_dotted(\"model.attn_implementation\", \"eager\")\n",
        "\n",
        "print(f\"Loaded config from: {CONFIG_PATH}\")\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Configuration Summary:\")\n",
        "print(\"=\"*60)\n",
        "print(cfg)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Initialize the Training Recipe\n",
        "\n",
        "The `TrainFinetuneRecipeForNextTokenPrediction` class orchestrates the entire training process:\n",
        "- Model loading and parallelization\n",
        "- Dataset and dataloader creation\n",
        "- Optimizer and scheduler setup\n",
        "- Checkpointing\n",
        "- Logging (WandB, MLflow, etc.)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create the recipe instance\n",
        "recipe = TrainFinetuneRecipeForNextTokenPrediction(cfg)\n",
        "print(\"‚úÖ Recipe created!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Setup the Recipe\n",
        "\n",
        "The `setup()` method initializes all components:\n",
        "- Distributed environment\n",
        "- Model and optimizer\n",
        "- Dataloaders\n",
        "- Schedulers\n",
        "- Checkpointer\n",
        "\n",
        "‚ö†Ô∏è **Note**: This step may download the model and dataset if not cached.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup all components\n",
        "print(\"Setting up recipe components...\")\n",
        "print(\"This may take a few minutes on first run (downloading model/dataset)\\n\")\n",
        "\n",
        "recipe.setup()\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ Recipe setup complete!\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Run Training\n",
        "\n",
        "Execute the training loop. This will:\n",
        "1. Iterate through epochs and batches\n",
        "2. Perform forward/backward passes\n",
        "3. Update model parameters\n",
        "4. Run validation at specified intervals\n",
        "5. Save checkpoints at specified intervals\n",
        "\n",
        "‚ö†Ô∏è **Warning**: Training can take a long time depending on your configuration!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run the training loop\n",
        "print(\"üèãÔ∏è Starting training...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "recipe.run_train_validation_loop()\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"‚úÖ Training complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Training Results\n",
        "\n",
        "After training completes, you can find:\n",
        "- **Checkpoints**: In the `checkpoints/` directory (or as configured)\n",
        "- **Training logs**: `training.jsonl` in the checkpoint directory\n",
        "- **Validation logs**: `validation.jsonl` in the checkpoint directory\n",
        "- **WandB/MLflow**: If configured, metrics are logged to these services\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display checkpoint location\n",
        "checkpoint_dir = recipe.checkpointer.config.checkpoint_dir\n",
        "print(f\"üìÅ Checkpoints saved to: {checkpoint_dir}\")\n",
        "\n",
        "# List checkpoint contents\n",
        "import os\n",
        "if os.path.exists(checkpoint_dir):\n",
        "    print(\"\\nCheckpoint directory contents:\")\n",
        "    for item in os.listdir(checkpoint_dir):\n",
        "        print(f\"  - {item}\")\n",
        "else:\n",
        "    print(\"\\n(Checkpoint directory not created yet)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üîó Useful Links\n",
        "\n",
        "- [NeMo AutoModel Documentation](https://docs.nvidia.com/nemo/automodel/latest/index.html)\n",
        "- [GitHub Repository](https://github.com/NVIDIA-NeMo/Automodel)\n",
        "- [LLM Fine-tuning Examples](https://github.com/NVIDIA-NeMo/Automodel/tree/main/examples/llm_finetune)\n",
        "- [VLM Fine-tuning Examples](https://github.com/NVIDIA-NeMo/Automodel/tree/main/examples/vlm_finetune)\n",
        "\n",
        "## Available Config Files\n",
        "\n",
        "Check out `examples/llm_finetune/` for many pre-built configurations:\n",
        "- **Llama**: llama3_1, llama3_2, llama3_3\n",
        "- **Mistral**: mistral, mixtral\n",
        "- **Qwen**: qwen2.5, qwen3\n",
        "- **Gemma**: gemma, gemma2, gemma3\n",
        "- **Phi**: phi2, phi3, phi4\n",
        "- And many more!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
