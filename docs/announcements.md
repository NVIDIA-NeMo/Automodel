# Announcements

- [Accelerating Large-Scale Mixture-of-Experts Training in PyTorch with NeMo Automodel](https://github.com/NVIDIA-NeMo/Automodel/discussions/777)
- [Challenges in Enabling PyTorch Native Pipeline Parallelism for Hugging Face Transformer Models](https://github.com/NVIDIA-NeMo/Automodel/discussions/589)
- [Google Gemma 3n: Efficient Multimodal Fine-tuning Made Simple](https://github.com/NVIDIA-NeMo/Automodel/discussions/494)
- [Fine-tune Hugging Face Models Instantly with Day-0 Support with NVIDIA NeMo AutoModel](https://github.com/NVIDIA-NeMo/Automodel/discussions/477)
