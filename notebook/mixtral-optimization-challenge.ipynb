{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 3: Mixtral-8x7B Performance Optimization Challenge\n",
        "\n",
        "## Objective\n",
        "Optimize the training performance of a **Mixtral-8x7B** Mixture of Experts (MoE) model to achieve the highest possible **Model FLOPs Utilization (MFU)**.\n",
        "\n",
        "## Workshop Structure\n",
        "1. **Baseline profiling**: Profile an unoptimized training run\n",
        "2. **Identify bottlenecks**: Use profiling tools to find inefficiencies\n",
        "3. **Apply optimizations**: Implement kernel and parallelism optimizations\n",
        "4. **Measure improvement**: Quantify MFU and throughput gains\n",
        "\n",
        "## Topics Covered\n",
        "- Distributed training parallelism (FSDP, EP, PP)\n",
        "- Performance profiling with torch.profiler and Nsight\n",
        "- Understanding arithmetic intensity\n",
        "- Developing strategic optimization plans\n",
        "\n",
        "## Grading (35 points)\n",
        "\n",
        "| Component | Points | Description |\n",
        "|-----------|--------|-------------|\n",
        "| Profiling Analysis | 5 | Try profile with nsys file |\n",
        "| MFU Improvement | 35 | Points based on achieved MFU (see rubric below) |\n",
        "\n",
        "### MFU Scoring Rubric (35 points)\n",
        "| MFU Achieved | Points |\n",
        "|--------------|--------|\n",
        "| â‰¥ 20.5% | 35 (full marks) |\n",
        "| 1% - 20.5% | Linear: (MFU - 1) / 19.5 Ã— 35 |\n",
        "| < 1% | 0 |\n",
        "\n",
        "## Hardware Requirements\n",
        "- 8x NVIDIA H100 GPUs (or equivalent)\n",
        "- Runtime container: `nvcr.io/nvidia/nemo-automodel:25.11`\n",
        "\n",
        "## Submission\n",
        "Submit the following files in your `submission/` folder:\n",
        "1. **Nsight profile** (`automodel_profile_*.nsys-rep`) â€” from Part 2\n",
        "2. **Optimized recipe** (`optimized_mixtral-8x7b-v0-1_benchmark.yaml`) â€” your configuration changes\n",
        "3. **Benchmark results** (`benchmark_results.json`) â€” auto-generated MFU output\n",
        "\n",
        "See **Part 5: Submission Checklist** for detailed instructions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!git clone https://github.com/NVIDIA-NeMo/Automodel.git\n",
        "!mkdir -p submission\n",
        "%cd Automodel\n",
        "!git fetch origin zhiyul/llm-optimization-workshop\n",
        "!git checkout zhiyul/llm-optimization-workshop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile ../submission/optimized_mixtral-8x7b-v0-1_benchmark.yaml\n",
        "# Copyright (c) 2025, NVIDIA CORPORATION.  All rights reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "# torchrun --nproc-per-node=8 --nnodes=1 nemo_automodel/recipes/llm/benchmark.py --config examples/llm_finetune/mistral/mixtral-8x7b-v0-1_benchmark.yaml\n",
        "seed: 42\n",
        "\n",
        "# Benchmark section\n",
        "benchmark:\n",
        "  warmup_steps: 5   \n",
        "  peak_tflops: 989  # H100: 989, A100: 312\n",
        "  nsys_start: -1    # Set to step number to profile (e.g., 10)\n",
        "  nsys_end: -1      # Set to end step (e.g., 15)\n",
        "  nsys_ranks: []    # e.g., [0] to profile rank 0\n",
        "  num_nodes: 1\n",
        "\n",
        "step_scheduler:\n",
        "  global_batch_size: 256\n",
        "  local_batch_size: 1   # open for change\n",
        "  ckpt_every_steps: 50\n",
        "  val_every_steps: 1000\n",
        "  max_steps: 10\n",
        "\n",
        "dist_env:\n",
        "  backend: nccl\n",
        "  timeout_minutes: 1\n",
        "\n",
        "rng:\n",
        "  _target_: nemo_automodel.components.training.rng.StatefulRNG\n",
        "  seed: 1111\n",
        "  ranked: true\n",
        "\n",
        "model:\n",
        "  _target_: nemo_automodel.components.models.mixtral.model.MixtralForCausalLM.from_pretrained\n",
        "  pretrained_model_name_or_path: mistralai/Mixtral-8x7B-v0.1\n",
        "  torch_dtype: bf16\n",
        "  trust_remote_code: true\n",
        "  router_aux_loss_coef: 0.0  # Disable aux/load-balancing loss\n",
        "\n",
        "checkpoint:\n",
        "  enabled: true\n",
        "  checkpoint_dir: checkpoints/\n",
        "  model_save_format: torch_save # torch_save or safetensors\n",
        "  save_consolidated: false\n",
        "  load_base_model: false\n",
        "\n",
        "distributed:\n",
        "  _target_: nemo_automodel.components.distributed.fsdp2.FSDP2Manager\n",
        "  dp_size: None\n",
        "  tp_size: 8\n",
        "  cp_size: 1\n",
        "  use_hf_tp_plan: true\n",
        "\n",
        "loss_fn:\n",
        "  _target_: nemo_automodel.components.loss.masked_ce.MaskedCrossEntropy\n",
        "\n",
        "# Use MockIterableDataset for benchmarking (faster, no I/O)\n",
        "dataset:\n",
        "  _target_: nemo_automodel.components.datasets.llm.mock_iterable_dataset.MockIterableDataset\n",
        "  vocab_size: 100\n",
        "  seq_len: 1024\n",
        "  num_samples: 1000000\n",
        "\n",
        "dataloader:\n",
        "  _target_: torch.utils.data.DataLoader\n",
        "  batch_size: null  # Dataset already yields batches\n",
        "  # Note: model_config will be auto-injected by train_ft.py for PP models\n",
        "\n",
        "optimizer:\n",
        "  _target_: torch.optim.Adam\n",
        "  betas: [0.9, 0.999]\n",
        "  eps: 1e-8\n",
        "  lr: 1.0e-5\n",
        "  weight_decay: 0\n",
        "\n",
        "lr_scheduler:\n",
        "  lr_decay_style: cosine\n",
        "  min_lr: 1.0e-6 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Validate your config - run this before submitting!\n",
        "import yaml\n",
        "from typing import Any\n",
        "\n",
        "# Fields that MUST remain unchanged\n",
        "FROZEN_FIELDS = {\n",
        "    \"seed\": 42,\n",
        "    \"benchmark.warmup_steps\": 5,\n",
        "    \"benchmark.peak_tflops\": 989,\n",
        "    \"benchmark.num_nodes\": 1,\n",
        "    \"step_scheduler.global_batch_size\": 256,\n",
        "    \"step_scheduler.max_steps\": 10,\n",
        "    \"model._target_\": \"nemo_automodel.components.models.mixtral.model.MixtralForCausalLM.from_pretrained\",\n",
        "    \"model.pretrained_model_name_or_path\": \"mistralai/Mixtral-8x7B-v0.1\",\n",
        "    \"model.torch_dtype\": \"bf16\",\n",
        "    \"dataset._target_\": \"nemo_automodel.components.datasets.llm.mock_iterable_dataset.MockIterableDataset\",\n",
        "    \"dataset.seq_len\": 1024,\n",
        "}\n",
        "\n",
        "def get_nested_value(config: dict, key_path: str) -> Any:\n",
        "    \"\"\"Get nested value from config using dot notation.\"\"\"\n",
        "    keys = key_path.split(\".\")\n",
        "    value = config\n",
        "    for key in keys:\n",
        "        if isinstance(value, dict) and key in value:\n",
        "            value = value[key]\n",
        "        else:\n",
        "            return None\n",
        "    return value\n",
        "\n",
        "def validate_config(config_path: str) -> bool:\n",
        "    \"\"\"Validate that the config only changes allowed fields.\"\"\"\n",
        "    with open(config_path, \"r\") as f:\n",
        "        config = yaml.safe_load(f)\n",
        "    \n",
        "    valid = True\n",
        "    print(\"ðŸ” Validating config...\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    # Check frozen fields\n",
        "    for field, expected in FROZEN_FIELDS.items():\n",
        "        actual = get_nested_value(config, field)\n",
        "        if actual != expected:\n",
        "            print(f\"âŒ FROZEN field '{field}' was changed!\")\n",
        "            print(f\"   Expected: {expected}, Got: {actual}\")\n",
        "            valid = False\n",
        "    \n",
        "    # Show distributed config\n",
        "    dist = config.get(\"distributed\", {})\n",
        "    print(f\"\\nðŸ“Š Parallelism config:\")\n",
        "    print(f\"   TP={dist.get('tp_size', 'None')}, \"\n",
        "          f\"PP={dist.get('pp_size', 'None')}, \"\n",
        "          f\"EP={dist.get('ep_size', 'None')}, \"\n",
        "          f\"CP={dist.get('cp_size', 'None')}\")\n",
        "    print(f\"   local_batch_size={config.get('step_scheduler', {}).get('local_batch_size', 1)}\")\n",
        "    \n",
        "    print(\"-\" * 50)\n",
        "    if valid:\n",
        "        print(\"âœ… Config is valid! Ready to benchmark.\")\n",
        "    else:\n",
        "        print(\"âŒ Config validation FAILED. Please fix the errors above.\")\n",
        "    \n",
        "    return valid\n",
        "\n",
        "# Run validation\n",
        "validate_config(\"../submission/optimized_mixtral-8x7b-v0-1_benchmark.yaml\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Part 1: Run baseline\n",
        "\n",
        "> **Tip**: Running in a **terminal** is recommended for real-time output. Notebook cells also work, but may incur additional memory overhead.\n",
        "\n",
        "The benchmark script will output:\n",
        "- Per-iteration timing and loss\n",
        "- Average MFU (Model FLOPs Utilization)\n",
        "- JSON summary saved to `../submission/benchmark_results.json` (configured in YAML)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "# Note: This is very slow with ~1% MFU - just run 2 steps for verification\n",
        "torchrun --nproc-per-node=8 --nnodes=1 \\\n",
        "    nemo_automodel/recipes/llm/benchmark.py \\\n",
        "    --config ../submission/optimized_mixtral-8x7b-v0-1_benchmark.yaml \\\n",
        "    --benchmark.warmup_steps=1 \\\n",
        "    --step_scheduler.max_steps=2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Part 2: Profiling Analysis (5 points)\n",
        "\n",
        "Use profiling tools to identify performance bottlenecks.\n",
        "\n",
        "### Profiling Tools Available\n",
        "1. **Nsight Systems**: GPU kernel analysis, timeline visualization\n",
        "2. **torch.profiler**: PyTorch operation profiling\n",
        "3. **CUDA Events**: Fine-grained kernel timing\n",
        "\n",
        "We choose to use Nsight System inside the lab.\n",
        "\n",
        "### Enable Nsight Profiling\n",
        "\n",
        "Modify the benchmark config to enable Nsight profiling:\n",
        "\n",
        "```yaml\n",
        "benchmark:\n",
        "  nsys_start: 6      # Start profiling at step 6 (after warmup)\n",
        "  nsys_end: 6        # End profiling at step 6\n",
        "  nsys_ranks: [0]    # Profile rank 0\n",
        "```\n",
        "\n",
        "### What to Look For\n",
        "Open the `.nsys-rep` file in Nsight Systems GUI for analysis (from https://developer.nvidia.com/nsight-systems/get-started) and find bottlenecks.\n",
        "\n",
        "Run with the command line as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "mkdir -p ../profile\n",
        "TIMESTAMP=$(date +\"%Y%m%d_%H%M%S\")\n",
        "PROFILE_FILE=\"../profile/automodel_profile_${TIMESTAMP}.nsys-rep\"\n",
        "\n",
        "nsys profile -s none \\\n",
        "    --trace=nvtx,cuda \\\n",
        "    --cudabacktrace=all \\\n",
        "    --cuda-graph-trace=node \\\n",
        "    --python-backtrace=cuda \\\n",
        "    --wait all \\\n",
        "    -o ${PROFILE_FILE} \\\n",
        "    --force-overwrite true \\\n",
        "    --capture-range=cudaProfilerApi \\\n",
        "    --capture-range-end=stop \\\n",
        "    torchrun --nproc-per-node=8 --nnodes=1 \\\n",
        "    nemo_automodel/recipes/llm/benchmark.py \\\n",
        "    --config ../submission/optimized_mixtral-8x7b-v0-1_benchmark.yaml \\\n",
        "    --benchmark.nsys_start=6 --benchmark.nsys_end=6 --benchmark.nsys_ranks=[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Part 3: Optimization Plan (35 points)\n",
        "\n",
        "Based on your profiling analysis, develop an optimization strategy and update the recipe ../submission/optimized_mixtral-8x7b-v0-1_benchmark.yaml\n",
        "\n",
        "### Hints for Available Optimization Techniques\n",
        "\n",
        "#### 1. Distributed Parallelism\n",
        "| Technique | Description | Config Key |\n",
        "|-----------|-------------|------------|\n",
        "| Tensor Parallel (TP) | Split model tensors across GPUs | `distributed.tp_size` |\n",
        "| Expert Parallel (EP) | Distribute MoE experts across GPUs | `distributed.ep_size` |\n",
        "| Pipeline Parallel (PP) | Split model layers across GPUs | `distributed.pp_size` |\n",
        "| Data Parallel (FSDP) | Replicate model, split data | `distributed.dp_size` |\n",
        "| Context Parallel (CP) | Split sequence across GPUs | `distributed.cp_size` |\n",
        "\n",
        "#### 2. Batch Optimization\n",
        "- **Local batch size**: Increase GPU utilization\n",
        "\n",
        "#### 3. Memory Optimizations\n",
        "- **activation_checkpointing**: Trade compute for memory\n",
        "\n",
        "#### 4. Kernel\n",
        "Go throught the code to see if there is any kernel option to try."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Part 4: Implement Optimizations (35 points)\n",
        "\n",
        "Create/update your optimized configuration and run the benchmark."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "torchrun --nproc-per-node=8 --nnodes=1 \\\n",
        "    nemo_automodel/recipes/llm/benchmark.py \\\n",
        "    --config ../submission/optimized_mixtral-8x7b-v0-1_benchmark.yaml \\\n",
        "    --benchmark.json_output_path=../submission/benchmark_results.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Part 5: Submission Checklist\n",
        "\n",
        "Before submitting, ensure your `submission/` folder contains all required files.\n",
        "\n",
        "### Required Files\n",
        "\n",
        "| File | Points | Description |\n",
        "|------|--------|-------------|\n",
        "| `automodel_profile_*.nsys-rep` | 5 | Nsight Systems profile from Part 2 |\n",
        "| `optimized_mixtral-8x7b-v0-1_benchmark.yaml` | 35 | Your optimized recipe configuration |\n",
        "| `benchmark_results.json` | â€” | Benchmark results with MFU (auto-generated) |\n",
        "\n",
        "### Step-by-Step Submission Guide\n",
        "\n",
        "**Step 1: Copy your Nsight profile to the submission folder**\n",
        "```bash\n",
        "cp ../profile/automodel_profile_*.nsys-rep ../submission/\n",
        "```\n",
        "\n",
        "**Step 2: Verify your optimized recipe**\n",
        "> The recipe is already saved via the `%%writefile` cell in Environment Setup.  \n",
        "> Re-run that cell if you made changes to your configuration.\n",
        "\n",
        "**Step 3: Run the final benchmark to generate results**\n",
        "```bash\n",
        "torchrun --nproc-per-node=8 --nnodes=1 \\\n",
        "    nemo_automodel/recipes/llm/benchmark.py \\\n",
        "    --config ../submission/optimized_mixtral-8x7b-v0-1_benchmark.yaml\n",
        "    --benchmark.json_output_path=../submission/benchmark_results.json\n",
        "```\n",
        "\n",
        "### Verify Your Submission\n",
        "\n",
        "```bash\n",
        "ls -la ../submission/\n",
        "```\n",
        "\n",
        "**Expected output:**\n",
        "```\n",
        "submission/\n",
        "â”œâ”€â”€ optimized_mixtral-8x7b-v0-1_benchmark.yaml  # Your optimized config\n",
        "â”œâ”€â”€ benchmark_results.json                       # Benchmark output with MFU score\n",
        "â””â”€â”€ automodel_profile_*.nsys-rep                 # Nsight profile for grading\n",
        "```\n",
        "\n",
        "### Grading Summary\n",
        "\n",
        "| Component | Points | Criteria |\n",
        "|-----------|--------|----------|\n",
        "| Nsight Profile | 5 | Valid `.nsys-rep` file submitted |\n",
        "| MFU Score | 35 | Based on `benchmark_results.json` (see rubric in intro) |\n",
        "| **Total** | **40** | |"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
