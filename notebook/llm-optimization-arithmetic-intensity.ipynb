{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 2: Arithmetic Intensity Visualization Lab\n",
        "\n",
        "By completing this assignment, you will:\n",
        "1. Understand the concept of **arithmetic intensity** and its impact on GPU performance\n",
        "2. Learn how to measure GPU compute performance (TFLOPS)\n",
        "3. Benchmark matrix operations and analyze the transition from memory-bounded to compute-bounded operations\n",
        "4. Create visualizations to analyze GPU utilization using the Roofline model\n",
        "\n",
        "## Instructions for Grading\n",
        "1. Complete **Task 1** and **Task 2** (the only TODO sections)\n",
        "2. Run all cells to generate the `answers.yaml` file\n",
        "3. Submit the `answers.yaml` file for grading\n",
        "\n",
        "## Grading (30 points)\n",
        "1. TFLOPS Calculation — *required but not graded*\n",
        "2. Arithmetic Intensity Calculation — **30 points**\n",
        "3. Visualization — *provided (no implementation needed)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Environment Setup\n",
        "\n",
        "runtime base container: `nvcr.io/nvidia/nemo-automodel:25.11`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install pandas plotly pyyaml -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot visualization\n",
        "import plotly.io as pio\n",
        "\n",
        "pio.renderers.default = \"notebook\"  # classic Jupyter Notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Dict, List\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "import torch\n",
        "import yaml\n",
        "from plotly.subplots import make_subplots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Background\n",
        "\n",
        "**Arithmetic Intensity (AI)** = FLOPs / Bytes Accessed\n",
        "\n",
        "For matrix multiplication `C = A @ B` where A and B are N×N matrices:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 1: Implement TFLOPS Calculation (15 points)\n",
        "\n",
        "**Formula**: \n",
        "- FLOPs for N×N matmul: `2 * N³`\n",
        "- TFLOPS (Tera FLOPs per Second) = `(FLOPs / time_seconds) / 1e12`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_tflops(matrix_size: int, time_seconds: float) -> float:\n",
        "    \"\"\"\n",
        "    Calculate achieved TFLOPS for matrix multiplication C = X @ X.\n",
        "\n",
        "    Args:\n",
        "        matrix_size: Size of square matrix (N x N)\n",
        "        time_seconds: Execution time in seconds\n",
        "\n",
        "    Returns:\n",
        "        Achieved TFLOPS (Tera FLOPs per second)\n",
        "    \"\"\"\n",
        "    # TODO: Implement this function\n",
        "    raise NotImplementedError(\"Complete Task 1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 2: Implement Arithmetic Intensity Calculation (15 points)\n",
        "\n",
        "**Formula**:\n",
        "- Bytes = `3 * N² * bytes_per_element` (2 bytes for FP16, 4 bytes for FP32)\n",
        "- AI = `FLOPs / Bytes`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_arithmetic_intensity(matrix_size: int, dtype: torch.dtype) -> float:\n",
        "    \"\"\"\n",
        "    Calculate arithmetic intensity (FLOPs per Byte) for matrix multiplication.\n",
        "\n",
        "    Args:\n",
        "        matrix_size: Size of square matrix (N x N)\n",
        "        dtype: Data type of matrix\n",
        "\n",
        "    Returns:\n",
        "        Arithmetic intensity (FLOPs/Byte)\n",
        "    \"\"\"\n",
        "    # TODO: Implement this function\n",
        "    raise NotImplementedError(\"Complete Task 2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Provided: Benchmark function\n",
        "def benchmark_matmul(\n",
        "    size: int,\n",
        "    dtype: torch.dtype,\n",
        "    device: torch.device,\n",
        "    num_warmup: int = 10,\n",
        "    num_iterations: int = 100,\n",
        ") -> Dict:\n",
        "    \"\"\"Benchmark matrix multiplication C = X @ X for a given size.\"\"\"\n",
        "    X = torch.randn(size, size, dtype=dtype, device=device)\n",
        "\n",
        "    # Warmup\n",
        "    for _ in range(num_warmup):\n",
        "        _ = torch.matmul(X, X)\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    start_event = torch.cuda.Event(enable_timing=True)\n",
        "    end_event = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "    start_event.record()\n",
        "    for _ in range(num_iterations):\n",
        "        result = torch.matmul(X, X)\n",
        "    end_event.record()\n",
        "    torch.cuda.synchronize()\n",
        "\n",
        "    elapsed_time_ms = start_event.elapsed_time(end_event)\n",
        "    avg_time_ms = elapsed_time_ms / num_iterations\n",
        "    avg_time_s = avg_time_ms / 1000.0\n",
        "\n",
        "    achieved_tflops = calculate_tflops(size, avg_time_s)\n",
        "    arithmetic_intensity = calculate_arithmetic_intensity(size, dtype)\n",
        "\n",
        "    return {\n",
        "        \"size\": size,\n",
        "        \"time_ms\": avg_time_ms,\n",
        "        \"achieved_tflops\": achieved_tflops,\n",
        "        \"arithmetic_intensity\": arithmetic_intensity,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Provided: Run benchmarks\n",
        "def run_benchmarks(sizes: List[int], dtype: torch.dtype = torch.float16) -> pd.DataFrame:\n",
        "    \"\"\"Run benchmarks for multiple matrix sizes.\"\"\"\n",
        "    if not torch.cuda.is_available():\n",
        "        raise RuntimeError(\"CUDA is not available!\")\n",
        "\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    props = torch.cuda.get_device_properties(device)\n",
        "    print(f\"GPU: {props.name}\")\n",
        "    print(f\"Total Memory: {props.total_memory / 1e9:.2f} GB\")\n",
        "    print(f\"\\nRunning benchmarks with dtype={dtype}\")\n",
        "    print(\"-\" * 60)\n",
        "    print(f\"{'Size':>8} {'Time(ms)':>12} {'TFLOPS':>10} {'AI':>12}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    results = []\n",
        "    for size in sizes:\n",
        "        result = benchmark_matmul(size, dtype, device)\n",
        "        results.append(result)\n",
        "        print(f\"{result['size']:8d} {result['time_ms']:12.4f} \"\n",
        "              f\"{result['achieved_tflops']:10.2f} \"\n",
        "              f\"{result['arithmetic_intensity']:12.2f}\")\n",
        "    print(\"-\" * 60)\n",
        "    return pd.DataFrame(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Provided: Visualization\n",
        "def plot_results(df: pd.DataFrame, peak_tflops: float = 989, peak_bandwidth_gbps: float = 3350):\n",
        "    \"\"\"Create interactive Plotly visualizations with 4 subplots.\"\"\"\n",
        "    fig = make_subplots(\n",
        "        rows=2, cols=2,\n",
        "        subplot_titles=(\n",
        "            \"Arithmetic Intensity vs Matrix Size\",\n",
        "            \"Achieved TFLOPS vs Matrix Size\",\n",
        "            \"Execution Time vs Matrix Size\",\n",
        "            \"Roofline Model\",\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    sizes = df.index.values\n",
        "\n",
        "    # Plot 1: Arithmetic Intensity vs Matrix Size\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=sizes, y=df[\"arithmetic_intensity\"], mode=\"lines+markers\",\n",
        "                   name=\"Arithmetic Intensity\", line=dict(color=\"blue\", width=3)),\n",
        "        row=1, col=1,\n",
        "    )\n",
        "\n",
        "    # Plot 2: Achieved TFLOPS vs Matrix Size\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=sizes, y=df[\"achieved_tflops\"], mode=\"lines+markers\",\n",
        "                   name=\"Achieved TFLOPS\", line=dict(color=\"green\", width=3)),\n",
        "        row=1, col=2,\n",
        "    )\n",
        "    fig.add_hline(y=peak_tflops, line_dash=\"dash\", line_color=\"red\",\n",
        "                  annotation_text=f\"Peak ({peak_tflops} TFLOPS)\", row=1, col=2)\n",
        "\n",
        "    # Plot 3: Execution Time vs Matrix Size\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=sizes, y=df[\"time_ms\"], mode=\"lines+markers\",\n",
        "                   name=\"Execution Time\", line=dict(color=\"red\", width=3)),\n",
        "        row=2, col=1,\n",
        "    )\n",
        "\n",
        "    # Plot 4: Roofline Model\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=df[\"arithmetic_intensity\"], y=df[\"achieved_tflops\"], mode=\"markers\",\n",
        "                   name=\"Achieved Performance\",\n",
        "                   marker=dict(size=12, color=df.index, colorscale=\"Viridis\", showscale=True,\n",
        "                              colorbar=dict(title=\"Matrix<br>Size\", x=1.15))),\n",
        "        row=2, col=2,\n",
        "    )\n",
        "\n",
        "    # Roofline (hardware limit)\n",
        "    ai_range = np.logspace(np.log10(df[\"arithmetic_intensity\"].min() * 0.5),\n",
        "                           np.log10(df[\"arithmetic_intensity\"].max() * 2), 100)\n",
        "    memory_bound = (peak_bandwidth_gbps / 1000) * ai_range\n",
        "    roofline = np.minimum(memory_bound, peak_tflops)\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=ai_range, y=roofline, mode=\"lines\", name=\"Roofline\",\n",
        "                   line=dict(color=\"red\", width=3, dash=\"dash\")),\n",
        "        row=2, col=2,\n",
        "    )\n",
        "\n",
        "    # Update axes\n",
        "    fig.update_xaxes(title_text=\"Matrix Size (N)\", type=\"log\", row=1, col=1)\n",
        "    fig.update_yaxes(title_text=\"Arithmetic Intensity (FLOPs/Byte)\", row=1, col=1)\n",
        "    fig.update_xaxes(title_text=\"Matrix Size (N)\", type=\"log\", row=1, col=2)\n",
        "    fig.update_yaxes(title_text=\"TFLOPS\", row=1, col=2)\n",
        "    fig.update_xaxes(title_text=\"Matrix Size (N)\", type=\"log\", row=2, col=1)\n",
        "    fig.update_yaxes(title_text=\"Time (ms)\", type=\"log\", row=2, col=1)\n",
        "    fig.update_xaxes(title_text=\"Arithmetic Intensity (FLOPs/Byte)\", type=\"log\", row=2, col=2)\n",
        "    fig.update_yaxes(title_text=\"Performance (TFLOPS)\", type=\"log\", row=2, col=2)\n",
        "\n",
        "    fig.update_layout(title_text=\"Matrix Multiplication Performance Analysis\",\n",
        "                      height=900, width=1400, showlegend=True)\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Run Benchmarks & Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Matrix sizes and run benchmarks\n",
        "sizes = [16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]\n",
        "\n",
        "df_fp16 = run_benchmarks(sizes, torch.float16).set_index(\"size\")\n",
        "df_fp32 = run_benchmarks(sizes, torch.float32).set_index(\"size\")\n",
        "\n",
        "df_fp16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization (H100 specs)\n",
        "peak_tflops = 989\n",
        "peak_bandwidth_gbps = 3350\n",
        "\n",
        "fig = plot_results(df_fp16, peak_tflops, peak_bandwidth_gbps)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Generate answers.yaml for Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate answers for grading - extract directly from benchmark DataFrames\n",
        "answers = {}\n",
        "\n",
        "for n in [16, 64, 256, 1024, 4096]:\n",
        "    answers[f\"ai_fp16_n{n}\"] = float(df_fp16.loc[n, \"arithmetic_intensity\"])\n",
        "    answers[f\"ai_fp32_n{n}\"] = float(df_fp32.loc[n, \"arithmetic_intensity\"])\n",
        "\n",
        "!mkdir -p submission\n",
        "# Save\n",
        "with open(\"submission/answers.yaml\", \"w\") as f:\n",
        "    yaml.dump(answers, f, default_flow_style=False, sort_keys=True)\n",
        "\n",
        "print(\"✅ answers.yaml generated!\")\n",
        "print(yaml.dump(answers, default_flow_style=False, sort_keys=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Submission\n",
        "\n",
        "Submit `submission` for grading. Grade with:\n",
        "```bash\n",
        "python grade_assignment.py submission\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
